# pages/2_Importer.py
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from supa import get_client
from utils import require_login

# ========= Config g√©n√©rale =========
st.set_page_config(page_title="Importer mes donn√©es", layout="wide")
KM_TOLERANCE = 0.3
ELEV_TOLERANCE = 40
TABLE = "journal"  # ta table r√©elle

# ========= Session / Auth =========
sb = get_client()
u = require_login(sb)  # bloque tant que pas connect√©
st.session_state["user"] = {"id": u.user.id, "email": u.user.email}
user = st.session_state.get("user")
if not user:
    st.stop()

# Appel optionnel au bouton logout si pr√©sent
try:
    from utils import sidebar_logout_bottom
    if callable(sidebar_logout_bottom):
        sidebar_logout_bottom()
except Exception:
    pass

st.title("üì• Importer mes donn√©es")
st.caption("Choisissez Garmin ou Strava, importez le CSV, g√©rez les doublons (ligne DB **au-dessus**, import **en dessous**).")

# ========= Helpers =========
def to_float(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    try:
        return float(str(x).strip().replace(",", "."))
    except:
        return None

def to_int(x):
    v = to_float(x)
    return int(round(v)) if v is not None else None

def hhmmss_to_seconds(s):
    if s is None or (isinstance(s, float) and np.isnan(s)): return None
    s = str(s).strip()
    if ":" not in s:
        try: return int(float(s))
        except: return None
    try:
        parts = [int(p) for p in s.split(":")]
        if len(parts) == 3: h, m, s2 = parts
        elif len(parts) == 2: h, m, s2 = 0, parts[0], parts[1]
        else: return None
        return h*3600 + m*60 + s2
    except: return None

def parse_date_any(x):
    if pd.isna(x): return None
    s = str(x).strip()
    fmts = [
        "%Y-%m-%d","%d/%m/%Y","%Y-%m-%d %H:%M:%S","%d/%m/%Y %H:%M:%S",
        "%m/%d/%Y","%m/%d/%Y %H:%M:%S","%Y-%m-%dT%H:%M:%S%z","%Y-%m-%dT%H:%M:%S"
    ]
    for f in fmts:
        try:
            return datetime.strptime(s, f).date().isoformat()
        except: pass
    try:
        dt = pd.to_datetime(s, errors="coerce", utc=False)
        return None if pd.isna(dt) else dt.date().isoformat()
    except:
        return None

def load_db_rows_for_date(day_iso):
    res = sb.table(TABLE).select("*").eq("user_id", user["id"]).eq("date", day_iso).execute()
    return res.data or []

def is_similar(existing, imported):
    if existing.get("date") != imported.get("date"):
        return False
    def close(a,b,tol):
        if a is None or b is None: return False
        return abs(a-b) <= tol
    km_ok = close(to_float(existing.get("distance_course_km")), to_float(imported.get("distance_course_km")), KM_TOLERANCE)
    dplus_ok = close(to_float(existing.get("dplus_course_m")), to_float(imported.get("dplus_course_m")), ELEV_TOLERANCE)
    dmoins_ok = close(to_float(existing.get("dmoins_course_m")), to_float(imported.get("dmoins_course_m")), ELEV_TOLERANCE)
    return km_ok and (dplus_ok or dmoins_ok)

def combine_rows(existing, imported):
    merged = existing.copy()
    for k in ["distance_course_km","dplus_course_m","dmoins_course_m","temps_course_min"]:
        ev, iv = existing.get(k), imported.get(k)
        if (ev is None or ev == "" or (isinstance(ev, float) and np.isnan(ev))) and iv not in [None, ""]:
            merged[k] = iv
    return merged

# ========= Parsers =========
def parse_garmin_csv(df):
    cols = {c.lower(): c for c in df.columns}
    def pick(*names):
        for n in names:
            if n.lower() in cols: return cols[n.lower()]
        return None
    c_date  = pick("Date","Activity Date","Start Time")
    c_km    = pick("Distance","Distance (km)","Distance (KM)")
    c_gain  = pick("Elevation Gain","Elev Gain","Total Ascent","D+ (m)")
    c_loss  = pick("Elevation Loss","Elev Loss","Total Descent","D- (m)")
    c_time  = pick("Elapsed Time","Duration","Moving Time")
    out = []
    for _, r in df.iterrows():
        d   = parse_date_any(r.get(c_date)) if c_date else None
        km  = to_float(r.get(c_km)) if c_km else None
        if km is not None and km > 200: km = km/1000.0  # safety si m√®tres
        dplus  = to_int(r.get(c_gain)) if c_gain else None
        dmoins = to_int(r.get(c_loss)) if c_loss else None
        sec    = hhmmss_to_seconds(r.get(c_time)) if c_time else None
        mins   = int(round(sec/60)) if sec is not None else None
        out.append({
            "date": d,
            "distance_course_km": km,
            "dplus_course_m": dplus,
            "dmoins_course_m": dmoins,
            "temps_course_min": mins,
        })
    df2 = pd.DataFrame(out)
    return df2.dropna(subset=["date","distance_course_km"]).reset_index(drop=True)

def parse_strava_csv(df):
    cols = {c.lower(): c for c in df.columns}
    def pick(*names):
        for n in names:
            if n.lower() in cols: return cols[n.lower()]
        return None
    c_type = pick("Activity Type","Type")
    if not c_type:
        st.error("Colonne 'Activity Type' (ou 'Type') introuvable dans le CSV Strava.")
        return pd.DataFrame(columns=["date","distance_course_km","dplus_course_m","dmoins_course_m","temps_course_min"])
    # filtre run (run, trail run, virtual run, etc.)
    df = df[df[c_type].astype(str).str.lower().str.contains("run")].copy()
    if df.empty:
        st.warning("Aucune activit√© de type 'run' trouv√©e dans le CSV Strava.")
        return pd.DataFrame(columns=["date","distance_course_km","dplus_course_m","dmoins_course_m","temps_course_min"])
    c_date = pick("Activity Date","Start Date Local","Start Date")
    c_dist = pick("Distance")
    c_gain = pick("Elevation Gain","Elev Gain","Total Ascent")
    c_loss = pick("Elevation Loss","Elev Loss","Total Descent")
    c_time = pick("Moving Time","Elapsed Time","Time")
    out = []
    for _, r in df.iterrows():
        d = parse_date_any(r.get(c_date)) if c_date else None
        dist_m = to_float(r.get(c_dist)) if c_dist else None
        km = dist_m/1000.0 if dist_m is not None else None
        dplus  = to_int(r.get(c_gain)) if c_gain else None
        dmoins = to_int(r.get(c_loss)) if c_loss else None
        sec    = hhmmss_to_seconds(r.get(c_time)) if c_time else None
        mins   = int(round(sec/60)) if sec is not None else None
        out.append({
            "date": d,
            "distance_course_km": km,
            "dplus_course_m": dplus,
            "dmoins_course_m": dmoins,
            "temps_course_min": mins,
        })
    df2 = pd.DataFrame(out)
    return df2.dropna(subset=["date","distance_course_km"]).reset_index(drop=True)

# ========= Traitement g√©n√©rique =========
def process_import(df_common, source_label):
    decisions = []
    for idx, row in df_common.iterrows():
        day = row["date"]
        existing_rows = load_db_rows_for_date(day)

        similar = None
        for ex in existing_rows:
            if is_similar(ex, row):
                similar = ex
                break

        st.markdown("---")
        st.subheader(f"{source_label} ‚Ä¢ {day} ‚Äî {row['distance_course_km']:.2f} km | D+ {row.get('dplus_course_m') or 0} m | D- {row.get('dmoins_course_m') or 0} m")

        if similar:
            st.info("üîÅ Doublon potentiel : compare **DB (haut)** vs **Import (bas)**")
            with st.container(border=True):
                st.markdown("**Dans la base (existant)**")
                c1,c2,c3,c4 = st.columns([1,1,1,1.2])
                c1.write(f"**Date**\n{similar.get('date')}")
                c2.write(f"**Km**\n{similar.get('distance_course_km')}")
                c3.write(f"**D+ / D-**\n{similar.get('dplus_course_m')} / {similar.get('dmoins_course_m')}")
                c4.write(f"**Dur√©e (min)**\n{similar.get('temps_course_min') or '-'}")

            with st.container(border=True):
                st.markdown("**Propos√© (import)**")
                c1,c2,c3,c4 = st.columns([1,1,1,1.2])
                c1.write(f"**Date**\n{row['date']}")
                c2.write(f"**Km**\n{row['distance_course_km']}")
                c3.write(f"**D+ / D-**\n{row.get('dplus_course_m')} / {row.get('dmoins_course_m')}")
                c4.write(f"**Dur√©e (min)**\n{row.get('temps_course_min') or '-'}")

            choice = st.radio(
                "Que faire ?",
                ["Ignorer", "Ins√©rer (quand m√™me)", "Remplacer (√©craser la DB)", "Combiner (compl√©ter l'existant)"],
                key=f"choice_{source_label}_{idx}",
                horizontal=True
            )
            decisions.append((row, similar, choice))
        else:
            st.success("üÜï Aucun doublon d√©tect√© ‚Äî vous pouvez ins√©rer.")
            with st.container(border=True):
                c1,c2,c3,c4 = st.columns([1,1,1,1.2])
                c1.write(f"**Date**\n{row['date']}")
                c2.write(f"**Km**\n{row['distance_course_km']}")
                c3.write(f"**D+ / D-**\n{row.get('dplus_course_m')} / {row.get('dmoins_course_m')}")
                c4.write(f"**Dur√©e (min)**\n{row.get('temps_course_min') or '-'}")
            decisions.append((row, None, "Ins√©rer (nouvelle ligne)"))

    if decisions and st.button("‚úÖ Appliquer les d√©cisions", key=f"apply_{source_label}"):
        n_ins, n_rep, n_comb, n_skip = 0,0,0,0
        for row, similar, choice in decisions:
            if choice.startswith("Ignorer"):
                n_skip += 1
                continue
            if similar is None and choice.startswith("Ins√©rer"):
                payload = {
                    "user_id": user["id"],
                    "date": row["date"],
                    "distance_course_km": row.get("distance_course_km"),
                    "dplus_course_m": row.get("dplus_course_m"),
                    "dmoins_course_m": row.get("dmoins_course_m"),
                    "temps_course_min": row.get("temps_course_min"),
                }
                sb.table(TABLE).insert(payload).execute()
                n_ins += 1
            elif similar is not None and choice.startswith("Ins√©rer (quand m√™me)"):
                payload = {
                    "user_id": user["id"],
                    "date": row["date"],
                    "distance_course_km": row.get("distance_course_km"),
                    "dplus_course_m": row.get("dplus_course_m"),
                    "dmoins_course_m": row.get("dmoins_course_m"),
                    "temps_course_min": row.get("temps_course_min"),
                }
                sb.table(TABLE).insert(payload).execute()
                n_ins += 1
            elif similar is not None and choice.startswith("Remplacer"):
                payload = {
                    "user_id": user["id"],
                    "date": row["date"],
                    "distance_course_km": row.get("distance_course_km"),
                    "dplus_course_m": row.get("dplus_course_m"),
                    "dmoins_course_m": row.get("dmoins_course_m"),
                    "temps_course_min": row.get("temps_course_min"),
                }
                sb.table(TABLE).update(payload).eq("id", similar["id"]).execute()
                n_rep += 1
            elif similar is not None and choice.startswith("Combiner"):
                merged = combine_rows(similar, row)
                payload = {
                    "user_id": user["id"],
                    "date": merged.get("date"),
                    "distance_course_km": merged.get("distance_course_km"),
                    "dplus_course_m": merged.get("dplus_course_m"),
                    "dmoins_course_m": merged.get("dmoins_course_m"),
                    "temps_course_min": merged.get("temps_course_min"),
                }
                sb.table(TABLE).update(payload).eq("id", similar["id"]).execute()
                n_comb += 1
        st.success(f"Termin√© : {n_ins} ins√©r√©(s), {n_rep} remplac√©(s), {n_comb} combin√©(s), {n_skip} ignor√©(s).")

# ========= UI : Garmin / Strava =========
tab_garmin, tab_strava = st.tabs(["üüß Garmin", "üü• Strava"])

with tab_garmin:
    st.subheader("Importer depuis Garmin (CSV d‚Äôactivit√©s)")
    garmin_file = st.file_uploader("D√©posez le CSV Garmin", type=["csv"], key="garmin_csv")
    if garmin_file is not None:
        try:
            df_raw = pd.read_csv(garmin_file)
        except UnicodeDecodeError:
            df_raw = pd.read_csv(garmin_file, encoding="latin1")
        st.write("Aper√ßu brut (Garmin):", df_raw.head())
        df_common = parse_garmin_csv(df_raw)
        if not df_common.empty:
            st.write("Pr√©paration (sch√©ma `journal`):", df_common.head())
            process_import(df_common, "Garmin")
        else:
            st.warning("Aucune ligne exploitable d√©tect√©e pour Garmin.")

with tab_strava:
    st.subheader("Importer depuis Strava (CSV global `activities.csv`)")
    strava_file = st.file_uploader("D√©posez le CSV Strava", type=["csv"], key="strava_csv")
    if strava_file is not None:
        try:
            df_raw = pd.read_csv(strava_file)
        except UnicodeDecodeError:
            df_raw = pd.read_csv(strava_file, encoding="latin1")
        st.write("Aper√ßu brut (Strava):", df_raw.head())
        df_common = parse_strava_csv(df_raw)
        if not df_common.empty:
            st.write("Pr√©paration (sch√©ma `journal`, uniquement *run*):", df_common.head())
            process_import(df_common, "Strava")
        else:
            st.warning("Aucune ligne exploitable (ou aucune activit√© 'run').")
